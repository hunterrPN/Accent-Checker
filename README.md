Predict the speakerâ€™s accent from audio using MFCCs, audio augmentation, and classical ML models.

This project predicts the accent of a speaker from a .wav audio sample using machine learning. It is built as a complete end-to-end pipeline including:

ğŸ§ Audio preprocessing and augmentation

ğŸ” Feature extraction (MFCC, ZCR, RMSE)

ğŸ§  Model training and evaluation (Random Forest / Logistic Regression)

ğŸ§ª Data versioning via DVC

ğŸŒ Streamlit app for real-time accent prediction




Features Extracted
From each audio file, we extract:

MFCCs (13 coefficients) â€” Mel Frequency Cepstral Coefficients

ZCR â€” Zero Crossing Rate

RMSE â€” Root Mean Square Energy

ğŸ”„ Audio Augmentation
To improve model generalization, we apply:

ğŸµ Time stretching

ğŸ“ˆ Pitch shifting

ğŸ”Š Noise addition

This ensures robustness to variations in speech.

ğŸ¤– Model Training
Models Compared:

RandomForestClassifier

LogisticRegression (final selected)

Evaluation Metrics:

Accuracy

Confusion matrix

Learning curve

Final Model: Logistic Regression

Test Accuracy: ~96%

ğŸ“¦ Version Control with DVC
used DVC to version:

Raw & interim datasets

Feature-engineered files

Trained models

